{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHuKj1qd21Ub",
        "outputId": "ec04ae18-13b4-4eff-f654-50f7d591a5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Looks like the sun finally located Trondheim ;-) hope summer's on it's way \", \"A long weekend begins. The sun is shining and I'm happy ! Exams soon \", 'to the beach we go! hope it stays nice... ', '@JBFutureboy I missed it  busted need to do a reunion tour. That would make my year. No joke.', \"Why I can't change my background image?? \"]\n",
            "['positif', 'négatif', 'positif', 'négatif', 'négatif']\n"
          ]
        }
      ],
      "source": [
        "# --- Extraction depuis CSV ---\n",
        "import csv\n",
        "tweets_data = []\n",
        "with open(\"balanced_tweets_200k.csv\", \"r\", encoding=\"latin1\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        if len(row) >= 6:\n",
        "            raw_label = row[0]\n",
        "            tweet = row[5]\n",
        "\n",
        "            if raw_label == \"0\":\n",
        "                label = \"négatif\"\n",
        "            elif raw_label == \"4\":\n",
        "                label = \"positif\"\n",
        "            else:\n",
        "                continue  # On ignore les autres labels\n",
        "\n",
        "            tweets_data.append((tweet, label))\n",
        "\n",
        "# --- Extraction des colonnes ---\n",
        "raw_tweets = [t[0] for t in tweets_data]\n",
        "labels = [t[1] for t in tweets_data]\n",
        "print(raw_tweets[:5])\n",
        "print(labels[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E-UapJ3Dmwq",
        "outputId": "7af320de-fb94-411c-9850-49ae6878f224"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=15000,\n",
        "    sublinear_tf=True,  # Atténuation de l'impact des termes fréquents\n",
        "    analyzer='word',\n",
        "    stop_words=[],\n",
        "    #min_df=0.2,           # Ignorer les termes rares\n",
        "    #max_df=5        # Éliminer les termes trop courants\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "01tl03lFwc_S"
      },
      "outputs": [],
      "source": [
        "data = tfidf.fit_transform(raw_tweets)\n",
        "X = data\n",
        "Y = [1 if label == \"positif\" else -1 for label in labels]\n",
        "n = data.shape[0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze-v7gxqr6-A"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Te7uP3xSjX"
      },
      "source": [
        "Régression logistique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8oNxULfQxJED",
        "outputId": "e76a1c4e-729b-409c-b526-e59a70421d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "{'C': 1, 'penalty': 'l1'}\n",
            "Test set accuracy: 79.89%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,               # Régularisation\n",
        "    #l1_ratio=0.4,  # Ratio de régularisation L1 # This parameter is not available for 'liblinear' solver\n",
        "    class_weight='balanced',  # Équilibrage des classes\n",
        "    solver='liblinear',  # Algorithme de résolution\n",
        "    max_iter=1000,       # Nombre maximal d'itérations\n",
        "    random_state=42      # For reproducibility\n",
        ")\n",
        "\n",
        "# Convert y_train and y_test to NumPy arrays with a specified dtype and map -1 to 0\n",
        "y_train_np = np.array([(1 if y == 1 else 0) for y in y_train], dtype=np.int32)\n",
        "y_test_np = np.array([(1 if y == 1 else 0) for y in y_test], dtype=np.int32)\n",
        "\n",
        "# Define param_grid before using it\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "grid = GridSearchCV(model, param_grid, cv=10, scoring='accuracy', verbose=1)\n",
        "grid.fit(X_train, y_train_np)\n",
        "print(grid.best_params_)\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = best_model.score(X_test, y_test_np)\n",
        "print(\"Test set accuracy: {:.2f}%\".format((accuracy) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CM-6DKDxn2j"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEUn2pjzxZWo",
        "outputId": "4b358b6f-cdbd-4bbb-dac5-b19e903b607f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,  # Nombre d'arbres\n",
        "    criterion='gini',    # Critère de split (gini ou entropy)\n",
        "    max_depth=None,      # Profondeur maximale de l'arbre\n",
        "    min_samples_split=2, # Nombre minimum d'échantillons requis pour spliter un nœud interne\n",
        "    min_samples_leaf=1,  # Nombre minimum d'échantillons requis à un nœud feuille\n",
        "    random_state=42      # Pour la reproductibilité\n",
        ")\n",
        "\n",
        "# Convert sparse matrices to dense arrays for cuML compatibility\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Convert y_train and y_test to NumPy arrays with a specified dtype\n",
        "y_train_np = np.array(y_train, dtype=np.float32)\n",
        "y_test_np = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "rf_model.fit(X_train_dense, y_train_np)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test_dense)\n",
        "\n",
        "accuracy_rf = rf_model.score(X_test_dense, y_test_np)\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQcdolri32EE"
      },
      "source": [
        "Mixture of Experts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gzbk163E34xF"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     26\u001b[39m moe_model = VotingClassifier(\n\u001b[32m     27\u001b[39m     estimators=[(\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m, expert1), (\u001b[33m'\u001b[39m\u001b[33mrf\u001b[39m\u001b[33m'\u001b[39m, expert2), (\u001b[33m'\u001b[39m\u001b[33msvm\u001b[39m\u001b[33m'\u001b[39m, expert3)],\n\u001b[32m     28\u001b[39m     voting=\u001b[33m'\u001b[39m\u001b[33mhard\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Train the Mixture of Experts model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mmoe_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Make predictions with the Mixture of Experts model\u001b[39;00m\n\u001b[32m     35\u001b[39m y_pred_moe = moe_model.predict(X_test)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     66\u001b[39m args_msg = [\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     69\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:419\u001b[39m, in \u001b[36mVotingClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    417\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:100\u001b[39m, in \u001b[36m_BaseVoting.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fit_params:\n\u001b[32m     96\u001b[39m             routed_params[name].fit[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = fit_params[\n\u001b[32m     97\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVoting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.named_estimators_ = Bunch()\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:39\u001b[39m, in \u001b[36m_fit_single_estimator\u001b[39m\u001b[34m(estimator, X, y, fit_params, message_clsname, message)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\svm\\_base.py:258\u001b[39m, in \u001b[36mBaseLibSVM.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[LibSVM]\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    257\u001b[39m seed = rnd.randint(np.iinfo(\u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m).max)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mself\u001b[39m.shape_fit_ = X.shape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\sklearn\\svm\\_base.py:377\u001b[39m, in \u001b[36mBaseLibSVM._sparse_fit\u001b[39m\u001b[34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[39m\n\u001b[32m    363\u001b[39m kernel_type = \u001b[38;5;28mself\u001b[39m._sparse_kernels.index(kernel)\n\u001b[32m    365\u001b[39m libsvm_sparse.set_verbosity_wrap(\u001b[38;5;28mself\u001b[39m.verbose)\n\u001b[32m    367\u001b[39m (\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_,\n\u001b[32m    369\u001b[39m     \u001b[38;5;28mself\u001b[39m.support_vectors_,\n\u001b[32m    370\u001b[39m     dual_coef_data,\n\u001b[32m    371\u001b[39m     \u001b[38;5;28mself\u001b[39m.intercept_,\n\u001b[32m    372\u001b[39m     \u001b[38;5;28mself\u001b[39m._n_support,\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m._probA,\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m._probB,\n\u001b[32m    375\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_status_,\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mself\u001b[39m._num_iter,\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m ) = \u001b[43mlibsvm_sparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_weight_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28mself\u001b[39m._warn_from_fit_status()\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclasses_\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_libsvm_sparse.pyx:218\u001b[39m, in \u001b[36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hakim\\miniforge3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:27\u001b[39m, in \u001b[36m_cs_matrix.__init__\u001b[39m\u001b[34m(self, arg1, shape, dtype, copy)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    base array/matrix class for compressed row- and column-oriented arrays/matrices\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     28\u001b[39m         _data_matrix.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(arg1):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Define the expert models\n",
        "expert1 = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    class_weight='balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "expert2 = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    criterion='gini',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Add another expert for diversification (e.g., an SVM)\n",
        "expert3 = SVC(probability=True, random_state=42)\n",
        "\n",
        "\n",
        "# Create the VotingClassifier (Mixture of Experts)\n",
        "# 'voting='hard'' uses majority voting, 'voting='soft'' uses predicted probabilities\n",
        "moe_model = VotingClassifier(\n",
        "    estimators=[('lr', expert1), ('rf', expert2), ('svm', expert3)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Train the Mixture of Experts model\n",
        "moe_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the Mixture of Experts model\n",
        "y_pred_moe = moe_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Mixture of Experts model\n",
        "accuracy_moe = moe_model.score(X_test, y_test)\n",
        "print(f\"Mixture of Experts Accuracy: {accuracy_moe:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vY7mwuM05EWo",
        "outputId": "24f114d1-2e2d-4b6f-9ef0-1fb14d4cfff9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d200d9cae34d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdense_layer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdropout_layer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the neural network model\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "dense_layer_1 = Dense(128, activation='relu')(input_layer)\n",
        "dropout_layer_1 = Dropout(0.5)(dense_layer_1)\n",
        "dense_layer_2 = Dense(64, activation='relu')(dropout_layer_1)\n",
        "dropout_layer_2 = Dropout(0.5)(dense_layer_2)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer_2) # Using sigmoid for binary classification\n",
        "\n",
        "nn_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='binary_crossentropy', # Using binary crossentropy for binary classification\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Since the target variables are -1 and 1, we need to convert them to 0 and 1 for binary crossentropy\n",
        "y_train_nn = [(1 if y == 1 else 0) for y in y_train]\n",
        "y_test_nn = [(1 if y == 1 else 0) for y in y_test]\n",
        "\n",
        "# Train the neural network model\n",
        "# Convert sparse matrix to dense array for neural network\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Convert NumPy arrays to TensorFlow Tensors\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_dense, dtype=tf.float32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_dense, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_nn, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test_nn, dtype=tf.float32)\n",
        "\n",
        "\n",
        "nn_model.fit(X_train_tensor, y_train_tensor, epochs=50, batch_size=2, verbose=0)\n",
        "\n",
        "# Evaluate the neural network model\n",
        "loss, accuracy_nn = nn_model.evaluate(X_test_tensor, y_test_tensor, verbose=0)\n",
        "print(f\"Neural Network Accuracy: {accuracy_nn:.2%}\")\n",
        "\n",
        "# Predict with the neural network model\n",
        "# The output is probabilities, convert to class labels (-1 or 1)\n",
        "y_pred_nn_prob = nn_model.predict(X_test_tensor)\n",
        "y_pred_nn = [(1 if prob > 0.5 else -1) for prob in y_pred_nn_prob]\n",
        "\n",
        "print(\"Neural Network Predictions:\", y_pred_nn)\n",
        "print(\"Actual Test Labels:\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMiScxQ06IxD"
      },
      "outputs": [],
      "source": [
        "# prompt: Do the same with XGBoost\n",
        "\n",
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# XGBoost requires DMatrix for its internal format\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Define XGBoost parameters\n",
        "# Using 'binary:logistic' for binary classification and converting labels to 0/1\n",
        "# for this loss function.\n",
        "# The y_train and y_test currently contain -1 and 1. We need to map them to 0 and 1.\n",
        "# 1 -> 1, -1 -> 0\n",
        "y_train_xgb = [(1 if y == 1 else 0) for y in y_train]\n",
        "y_test_xgb = [(1 if y == 1 else 0) for y in y_test]\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train_xgb)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test_xgb)\n",
        "\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',  # Binary classification with logistic regression\n",
        "    'eval_metric': 'logloss',        # Evaluation metric\n",
        "    'eta': 0.1,                      # Learning rate\n",
        "    'max_depth': 3,                  # Maximum depth of trees\n",
        "    'subsample': 0.8,                # Subsample ratio of the training instance\n",
        "    'colsample_bytree': 0.8,         # Subsample ratio of columns when constructing each tree\n",
        "    'seed': 42                       # Random seed for reproducibility\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "num_rounds = 100  # Number of boosting rounds\n",
        "watchlist = [(dtrain, 'train'), (dtest, 'eval')] # Watchlist to monitor performance\n",
        "\n",
        "xgb_model = xgb.train(params, dtrain, num_rounds, evals=watchlist, early_stopping_rounds=10, verbose_eval=False)\n",
        "\n",
        "# Make predictions\n",
        "# XGBoost outputs probabilities for binary:logistic\n",
        "y_pred_xgb_prob = xgb_model.predict(dtest)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_xgb = [1 if prob > 0.5 else 0 for prob in y_pred_xgb_prob]\n",
        "\n",
        "# Convert back to the original -1, 1 format for comparison with y_test\n",
        "y_pred_xgb_original = [1 if pred == 1 else -1 for pred in y_pred_xgb]\n",
        "\n",
        "\n",
        "# Evaluate the model (using scikit-learn's accuracy_score)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_xgb = accuracy_score(y_test_xgb, y_pred_xgb) # Use 0/1 for evaluation\n",
        "\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.2%}\")\n",
        "\n",
        "print(\"XGBoost Predictions (0/1):\", y_pred_xgb)\n",
        "print(\"XGBoost Predictions (-1/1):\", y_pred_xgb_original)\n",
        "print(\"Actual Test Labels (-1/1):\", y_test)\n",
        "print(\"Actual Test Labels (0/1):\", y_test_xgb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9CYb1hR6NJ9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# kNN Classifier\n",
        "knn_model = KNeighborsClassifier(\n",
        "    n_neighbors=3,  # Number of neighbors to consider\n",
        "    weights='uniform', # Weight function used in prediction (uniform or distance)\n",
        "    algorithm='auto', # Algorithm used to compute the nearest neighbors\n",
        "    leaf_size=30,     # Leaf size passed to BallTree or KDTree\n",
        "    p=2,              # Power parameter for the Minkowski metric (p=2 for Euclidean distance)\n",
        "    metric='minkowski' # Distance metric\n",
        ")\n",
        "\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "accuracy_knn = knn_model.score(X_test, y_test)\n",
        "print(f\"kNN Accuracy: {accuracy_knn:.2%}\")\n",
        "print(\"kNN Predictions:\", y_pred_knn)\n",
        "print(\"Actual Test Labels:\", y_test)\n",
        "param_grid = {'n_neighbors': list(range(1, 31,2))}\n",
        "grid = GridSearchCV(knn_model, param_grid, cv=10, scoring='MCC', verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n",
        "best_knn = grid.best_estimator_\n",
        "y_pred = best_knn.predict(X_test)\n",
        "print(\"Test set accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4OCySz96V1z"
      },
      "outputs": [],
      "source": [
        "# prompt: Do the same with SVM\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVC(\n",
        "    C=1.0,                 # Régularisation (plus C est grand, moins la régularisation est forte)\n",
        "    kernel='linear',       # Type de noyau ('linear', 'poly', 'rbf', 'sigmoid')\n",
        "    gamma='scale',         # Coefficient de noyau pour 'rbf', 'poly', 'sigmoid'\n",
        "    probability=True,      # Permet de calculer les probabilités de classe\n",
        "    random_state=42        # Pour la reproductibilité\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "accuracy_svm = svm_model.score(X_test, y_test)\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.2%}\")\n",
        "print(\"SVM Predictions:\", y_pred_svm)\n",
        "print(\"Actual Test Labels:\", y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
